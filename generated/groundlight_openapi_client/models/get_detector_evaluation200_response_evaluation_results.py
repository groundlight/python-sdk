# coding: utf-8

"""
    Groundlight API

    Groundlight makes it simple to understand images. You can easily create computer vision detectors just by describing what you want to know using natural language.

    The version of the OpenAPI document: 0.18.2
    Contact: support@groundlight.ai
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from pydantic import BaseModel, ConfigDict, StrictFloat, StrictInt
from typing import Any, ClassVar, Dict, List, Optional, Union
from typing import Optional, Set
from typing_extensions import Self


class GetDetectorEvaluation200ResponseEvaluationResults(BaseModel):
    """
    GetDetectorEvaluation200ResponseEvaluationResults
    """  # noqa: E501

    eval_timestamp: Optional[datetime] = None
    total_ground_truth_examples: Optional[StrictInt] = None
    total_labeled_examples: Optional[StrictInt] = None
    kfold_pooled__balanced_accuracy: Optional[Union[StrictFloat, StrictInt]] = None
    kfold_pooled__positive_accuracy: Optional[Union[StrictFloat, StrictInt]] = None
    kfold_pooled__negative_accuracy: Optional[Union[StrictFloat, StrictInt]] = None
    precision__mean: Optional[Union[StrictFloat, StrictInt]] = None
    recall__mean: Optional[Union[StrictFloat, StrictInt]] = None
    roc_auc__mean: Optional[Union[StrictFloat, StrictInt]] = None
    balanced_system_accuracies: Optional[Dict[str, Any]] = None
    positive_system_accuracies: Optional[Dict[str, Any]] = None
    negative_system_accuracies: Optional[Dict[str, Any]] = None
    mean_absolute_error__mean: Optional[Union[StrictFloat, StrictInt]] = None
    objdet_precision__mean: Optional[Union[StrictFloat, StrictInt]] = None
    objdet_recall__mean: Optional[Union[StrictFloat, StrictInt]] = None
    objdet_f1_score__mean: Optional[Union[StrictFloat, StrictInt]] = None
    class_accuracies: Optional[Dict[str, Any]] = None
    confusion_dict: Optional[Dict[str, Any]] = None
    num_examples_per_class: Optional[Dict[str, Any]] = None
    __properties: ClassVar[List[str]] = [
        "eval_timestamp",
        "total_ground_truth_examples",
        "total_labeled_examples",
        "kfold_pooled__balanced_accuracy",
        "kfold_pooled__positive_accuracy",
        "kfold_pooled__negative_accuracy",
        "precision__mean",
        "recall__mean",
        "roc_auc__mean",
        "balanced_system_accuracies",
        "positive_system_accuracies",
        "negative_system_accuracies",
        "mean_absolute_error__mean",
        "objdet_precision__mean",
        "objdet_recall__mean",
        "objdet_f1_score__mean",
        "class_accuracies",
        "confusion_dict",
        "num_examples_per_class",
    ]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GetDetectorEvaluation200ResponseEvaluationResults from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # set to None if total_ground_truth_examples (nullable) is None
        # and model_fields_set contains the field
        if self.total_ground_truth_examples is None and "total_ground_truth_examples" in self.model_fields_set:
            _dict["total_ground_truth_examples"] = None

        # set to None if total_labeled_examples (nullable) is None
        # and model_fields_set contains the field
        if self.total_labeled_examples is None and "total_labeled_examples" in self.model_fields_set:
            _dict["total_labeled_examples"] = None

        # set to None if kfold_pooled__positive_accuracy (nullable) is None
        # and model_fields_set contains the field
        if self.kfold_pooled__positive_accuracy is None and "kfold_pooled__positive_accuracy" in self.model_fields_set:
            _dict["kfold_pooled__positive_accuracy"] = None

        # set to None if kfold_pooled__negative_accuracy (nullable) is None
        # and model_fields_set contains the field
        if self.kfold_pooled__negative_accuracy is None and "kfold_pooled__negative_accuracy" in self.model_fields_set:
            _dict["kfold_pooled__negative_accuracy"] = None

        # set to None if precision__mean (nullable) is None
        # and model_fields_set contains the field
        if self.precision__mean is None and "precision__mean" in self.model_fields_set:
            _dict["precision__mean"] = None

        # set to None if recall__mean (nullable) is None
        # and model_fields_set contains the field
        if self.recall__mean is None and "recall__mean" in self.model_fields_set:
            _dict["recall__mean"] = None

        # set to None if roc_auc__mean (nullable) is None
        # and model_fields_set contains the field
        if self.roc_auc__mean is None and "roc_auc__mean" in self.model_fields_set:
            _dict["roc_auc__mean"] = None

        # set to None if balanced_system_accuracies (nullable) is None
        # and model_fields_set contains the field
        if self.balanced_system_accuracies is None and "balanced_system_accuracies" in self.model_fields_set:
            _dict["balanced_system_accuracies"] = None

        # set to None if positive_system_accuracies (nullable) is None
        # and model_fields_set contains the field
        if self.positive_system_accuracies is None and "positive_system_accuracies" in self.model_fields_set:
            _dict["positive_system_accuracies"] = None

        # set to None if negative_system_accuracies (nullable) is None
        # and model_fields_set contains the field
        if self.negative_system_accuracies is None and "negative_system_accuracies" in self.model_fields_set:
            _dict["negative_system_accuracies"] = None

        # set to None if mean_absolute_error__mean (nullable) is None
        # and model_fields_set contains the field
        if self.mean_absolute_error__mean is None and "mean_absolute_error__mean" in self.model_fields_set:
            _dict["mean_absolute_error__mean"] = None

        # set to None if objdet_precision__mean (nullable) is None
        # and model_fields_set contains the field
        if self.objdet_precision__mean is None and "objdet_precision__mean" in self.model_fields_set:
            _dict["objdet_precision__mean"] = None

        # set to None if objdet_recall__mean (nullable) is None
        # and model_fields_set contains the field
        if self.objdet_recall__mean is None and "objdet_recall__mean" in self.model_fields_set:
            _dict["objdet_recall__mean"] = None

        # set to None if objdet_f1_score__mean (nullable) is None
        # and model_fields_set contains the field
        if self.objdet_f1_score__mean is None and "objdet_f1_score__mean" in self.model_fields_set:
            _dict["objdet_f1_score__mean"] = None

        # set to None if class_accuracies (nullable) is None
        # and model_fields_set contains the field
        if self.class_accuracies is None and "class_accuracies" in self.model_fields_set:
            _dict["class_accuracies"] = None

        # set to None if confusion_dict (nullable) is None
        # and model_fields_set contains the field
        if self.confusion_dict is None and "confusion_dict" in self.model_fields_set:
            _dict["confusion_dict"] = None

        # set to None if num_examples_per_class (nullable) is None
        # and model_fields_set contains the field
        if self.num_examples_per_class is None and "num_examples_per_class" in self.model_fields_set:
            _dict["num_examples_per_class"] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GetDetectorEvaluation200ResponseEvaluationResults from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "eval_timestamp": obj.get("eval_timestamp"),
            "total_ground_truth_examples": obj.get("total_ground_truth_examples"),
            "total_labeled_examples": obj.get("total_labeled_examples"),
            "kfold_pooled__balanced_accuracy": obj.get("kfold_pooled__balanced_accuracy"),
            "kfold_pooled__positive_accuracy": obj.get("kfold_pooled__positive_accuracy"),
            "kfold_pooled__negative_accuracy": obj.get("kfold_pooled__negative_accuracy"),
            "precision__mean": obj.get("precision__mean"),
            "recall__mean": obj.get("recall__mean"),
            "roc_auc__mean": obj.get("roc_auc__mean"),
            "balanced_system_accuracies": obj.get("balanced_system_accuracies"),
            "positive_system_accuracies": obj.get("positive_system_accuracies"),
            "negative_system_accuracies": obj.get("negative_system_accuracies"),
            "mean_absolute_error__mean": obj.get("mean_absolute_error__mean"),
            "objdet_precision__mean": obj.get("objdet_precision__mean"),
            "objdet_recall__mean": obj.get("objdet_recall__mean"),
            "objdet_f1_score__mean": obj.get("objdet_f1_score__mean"),
            "class_accuracies": obj.get("class_accuracies"),
            "confusion_dict": obj.get("confusion_dict"),
            "num_examples_per_class": obj.get("num_examples_per_class"),
        })
        return _obj
