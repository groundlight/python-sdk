# Getting Started with Groundlight

## Build Computer Vision Applications in Minutes with Groundlight's Python SDK

Welcome to Groundlight AI! This guide will help you build your first computer vision application quickly and easily using our Python SDK.

Don't code? [Contact our team](mailto:support@groundlight.ai) and we'll build a custom solution for you.

### Prerequisites
Before you begin, make sure you have:
1. A [Groundlight account](https://dashboard.groundlight.ai/)!
2. An API token from the [Groundlight dashboard](https://dashboard.groundlight.ai/reef/my-account/api-tokens). See our [guide to API Tokens](http://localhost:3000/python-sdk/docs/getting-started/api-tokens) for more info.
3. Python 3.9 or newer installed

### Installing the Groundlight SDK

You can install the Groundlight SDK via pip. When installing python packages, it is a best practice to install them
inside of virtual environments. Run the following in the command line to create a new environment:
```bash
python3 -m venv groundlight-env
```

Activate the virtual environment using
- On macOS or Linux, `source groundlight-env/bin/activate`
- On Windows, `.\groundlight-env\Scripts\activate`

Now, you can install the Groundlight SDK using pip:
```bash
pip install groundlight
```

For more detailed installation instructions, see the [installation guide](/docs/installation/).

### Authentication
The Groundlight SDK uses API tokens to authenticate your requests to the Groundlight API.
When you make API calls, the SDK automatically uses your token to verify your identity and permissions. It
does this by checking the `GROUNDLIGHT_API_TOKEN` environment variable. In order to set this environment
variable, run:
```bash
# MacOS / Linux
export GROUNDLIGHT_API_TOKEN='your-api-token'
```
```powershell
# Windows
setx GROUNDLIGHT_API_TOKEN "your-api-token"
```
:::important
Keep your API token secure! Anyone who has access to it can impersonate you and can access to your Groundlight data.
:::

### Call the Groundlight API

Call the Groundlight API by creating a `Detector` and submitting an `ImageQuery`. A `Detector` represents a specific
visual question you want to answer, while an `ImageQuery` is a request to analyze an image with that question.

The Groundlight system is designed to provide consistent, highly confident answers for similar images
(such as frames from the same camera) when asked the same question repeatedly. This makes it ideal for
monitoring scenarios where you need reliable visual detection.

Let's see how to use Groundlight to analyze an image:
```python title="ask.py"
from groundlight import Groundlight, Detector, ImageQuery
from framegrab import FrameGrabber

gl = Groundlight()
detector: Detector = gl.get_or_create_detector(
    name="eagle-detector",
    query="Is there an eagle visible?",
)

# Big Bear Bald Eagle Nest live-stream
youtube_live_url = 'https://www.youtube.com/watch?v=B4-L2nfGcuE'

config = {
    'input_type': 'youtube_live',
    'id': {'youtube_url': youtube_live_url},
}

with FrameGrabber.create_grabber({
    'input_type': 'youtube_live', 'id': {'youtube_url': youtube_live_url},
}) as grabber:
    frame = grabber.grab()
    if frame is None:
        raise Exception("No frame captured")

image_query = gl.submit_image_query(detector=detector, image=frame)

print(f"The answer is {image_query.result.label}")
print(image_query)
```

Run the code using `python ask.py`. The code will submit an image from the live-stream to the Groundlight API and print the result:
```
The answer is YES
ImageQuery(
    id='iq_2pL5wwlefaOnFNQx1X6awTOd119',
    query="Is there an eagle visible?,
    detector_id='det_2owcsT7XCsfFlu7diAKgPKR4BXY',
    result=BinaryClassificationResult(
        confidence=0.9995857543478209,
        label=<Label.YES: 'YES'>
    ),
    created_at=datetime.datetime(2025, 2, 25, 11, 5, 57, 38627, tzinfo=tzutc()),
    patience_time=30.0,
    confidence_threshold=0.9,
    type=<ImageQueryTypeEnum.image_query: 'image_query'>,
    result_type=<ResultTypeEnum.binary_classification: 'binary_classification'>,
    metadata=None
)
```

For more information on the Groundlight SDK, see the [API Reference](/docs/api-reference/), or check out our [guide to building applications with the Groundlight SDK](/docs/guide/).

### Using Your Computer Vision Application

Congratulations! You now have a fully functional computer vision application. You can easily customize the code and configure detectors for your specific use cases.

Monitor and enhance your detector's performance through the [Groundlight Dashboard](https://dashboard.groundlight.ai/).
Groundlight's human-in-the-loop technology intelligently monitors your image feed for anomalies and unexpected changes.
By reviewing and verifying results, you continuously improve the system's accuracy. Through the dashboard, you can also
[configure text and email notifications](/docs/guide/alerts) to alert you when important events are detected in your video stream.

### Next Steps

Now that you've built your first application, you can:
    1. Learn how to [write effective queries](/docs/getting-started/writing-queries).
    2. Proceed to [capture images from a wide variety of sources](/docs/guide/grabbing-images) using [`framegrab`](https://github.com/groundlight/framegrab).
    3. Read our guide to [confidence thresholds](/docs/guide/managing-confidence).



Ready to explore more possibilities? Visit our [Guides](https://www.groundlight.ai/guides) to discover sample
applications built with Groundlight AI â€” from [industrial inspection workflows](https://www.groundlight.ai/blog/lkq-corporation-uses-groundlight-ai-to-revolutionize-quality-control-and-inspection)
to [hummingbird detection systems](https://www.groundlight.ai/guides/detecting-hummingbirds-with-groundlight-ai).