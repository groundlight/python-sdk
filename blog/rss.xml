<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Groundlight Blog</title>
        <link>https://code.groundlight.ai/python-sdk/blog</link>
        <description>Groundlight Blog</description>
        <lastBuildDate>Tue, 02 Jan 2024 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Linux OS Images for Computer Vision on Raspberry Pi]]></title>
            <link>https://code.groundlight.ai/python-sdk/blog/raspberry-pi-computer-vision</link>
            <guid>https://code.groundlight.ai/python-sdk/blog/raspberry-pi-computer-vision</guid>
            <pubDate>Tue, 02 Jan 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[Groundlight simplifies the setup process by providing ready-to-use OS images for Raspberry Pi]]></description>
            <content:encoded><![CDATA[<p>Happy New Year everybody!  If you got a fancy new Raspberry Pi 5 for Christmas, you might be wondering what to do with it.  Well, we have a suggestion:  build a computer vision application with it!  And we have all the tools you need to get started.</p>
<p>Raspberry Pi offers a great platform for computer vision (CV), ranging from home hobby projects to serious industrial applications. However, setting up a Raspberry Pi for computer vision can be a time-consuming process. <a href="https://github.com/groundlight/groundlight-pi-gen" target="_blank" rel="noopener noreferrer">Groundlight Pi-Gen</a>, simplifies the setup process by providing ready-to-use OS images for Raspberry Pi.</p>
<p>(Note that here, when we say "image" we mean an OS image, which is a file containing a snapshot of an operating system - linux - that can be installed onto a new machine.  These are not photos or pictures, which are also of course important in computer vision.  Oh jargon...)</p>
<h2 class="anchor anchorWithStickyNavbar_FNw8" id="raspberry-pi-os-images-pre-built-with-computer-vision-software">Raspberry Pi OS Images pre-built with Computer Vision Software<a href="https://code.groundlight.ai/python-sdk/blog/raspberry-pi-computer-vision#raspberry-pi-os-images-pre-built-with-computer-vision-software" class="hash-link" aria-label="Direct link to Raspberry Pi OS Images pre-built with Computer Vision Software" title="Direct link to Raspberry Pi OS Images pre-built with Computer Vision Software">‚Äã</a></h2>
<p>To download a Linux image for your Raspberry Pi, loaded with all the software you need for computer vision,
go to the <a href="https://github.com/groundlight/groundlight-pi-gen/releases" target="_blank" rel="noopener noreferrer">releases</a> section in Groundlight Pi-Gen to find Raspberry Pi OS images (<code>.img.xz</code> files) that have pre-configured software environments for computer vision. These images are ready to be flashed onto a Raspberry Pi.</p>
<p>These include a fast, modern version of python (3.11), along with key libraries like <a href="https://opencv.org/" target="_blank" rel="noopener noreferrer">OpenCV</a> for classic algorithms and device management, <a href="https://numpy.org/" target="_blank" rel="noopener noreferrer">Numpy</a> for fast math, <a href="https://code.groundlight.ai/python-sdk/blog/introducing-framegrab" target="_blank" rel="noopener noreferrer">FrameGrab</a> for declarative access to image sources, and of course <a href="https://pypi.org/project/groundlight/" target="_blank" rel="noopener noreferrer">Groundlight</a> for fully-managed visual understanding models.  We've set up a <code>venv</code> for you to avoid the dreaded "externally-managed-environment" error which plagues many newer python versions, while still letting you use good-old <code>pip</code> to add more.  (We like <code>poetry</code> and <code>conda</code>, and these will also work fine if you prefer them.)</p>
<p>There are several flavors of OS image available.  The smaller ones are suitable for headless use, while the larger ones include a desktop GUI with a browser.  The key differences are the size of the download and the amount of time it takes to flash the image onto a microSD card.  The <a href="https://github.com/groundlight/groundlight-pi-gen/releases" target="_blank" rel="noopener noreferrer">available flavors in the current release</a> are:</p>
<p><img loading="lazy" alt="Comparison of Groundlight Pi-Gen OS image flavors" src="https://code.groundlight.ai/python-sdk/assets/images/download-assets-86ee9b658158239e80bba62f01c5c84d.png" title="Comparison of Groundlight Pi-Gen OS image flavors" width="756" height="229" class="img_wQsy"></p>
<ul>
<li><code>desktop</code>: Image with Groundlight MNS and a desktop GUI with a browser.  Appropriate for a Raspberry Pi with a screen attached.</li>
<li><code>mns-headless</code>: Image with Groundlight Monitoring Notification Server (MNS) for headless use.</li>
<li><code>sdk-only</code>: Minimal image with the Python SDK and core libraries.  Suitable for headless use on smaller Raspberry Pi models such as the Pi Zero.</li>
</ul>
<p>A couple more flavors you might be interested in: We're planning a <a href="https://github.com/groundlight/groundlight-pi-gen/issues/15" target="_blank" rel="noopener noreferrer">kiosk mode</a> for the desktop image, so that you can run a Groundlight MNS instance on a Raspberry Pi with a screen attached, and have it automatically start up in a browser.<br>
<!-- -->Also note that the <code>edge</code> version which will download and run the ML models locally is not yet supported on Raspberry Pi, because the edge models requires a CUDA GPU.</p>
<h2 class="anchor anchorWithStickyNavbar_FNw8" id="flashing-the-os-image-onto-a-microsd-card">Flashing the OS Image onto a microSD Card<a href="https://code.groundlight.ai/python-sdk/blog/raspberry-pi-computer-vision#flashing-the-os-image-onto-a-microsd-card" class="hash-link" aria-label="Direct link to Flashing the OS Image onto a microSD Card" title="Direct link to Flashing the OS Image onto a microSD Card">‚Äã</a></h2>
<p>Once you have <a href="https://github.com/groundlight/groundlight-pi-gen/releases" target="_blank" rel="noopener noreferrer">downloaded your image file</a>, the next step is to flash it onto a microSD card.  To do this,
download the <a href="https://www.raspberrypi.com/software/" target="_blank" rel="noopener noreferrer">Raspberry Pi Imager</a> software.</p>
<p><img loading="lazy" alt="Raspberry Pi Imager home screen" src="https://code.groundlight.ai/python-sdk/assets/images/rpi-imager-1-d738296f119f954f0ca471bef0285ef6.png" title="Raspberry Pi Imager home screen" width="792" height="590" class="img_wQsy"></p>
<p>After selecting your hardware type under "Choose Device", click "Choose OS" and scroll to the bottom to "Use custom".</p>
<p><img loading="lazy" alt="Raspberry Pi Imager use custom OS" src="https://code.groundlight.ai/python-sdk/assets/images/rpi-imager-2-fb4df452d3827613ed12c4b987d1860d.png" title="Raspberry Pi Imager use custom OS" width="792" height="590" class="img_wQsy"></p>
<p>Then select the <code>.img.xz</code> file you downloaded.</p>
<p><img loading="lazy" alt="Raspberry Pi Imager pick OS file" src="https://code.groundlight.ai/python-sdk/assets/images/rpi-imager-3-b1b43de59a5facb701f256795a1e47fe.png" title="Raspberry Pi Imager pick OS file" width="683" height="481" class="img_wQsy"></p>
<p>Then choose your microSD card with the "Choose Storage" button, and then click "Next".<br>
<!-- -->You'll get a prompt asking "Use OS customization?" which is optional, but very cool.  Choose "Edit settings", and you
can set your Wi-Fi credentials, enable SSH login with a public key.</p>
<p><img loading="lazy" alt="Rasterberry Pi Imager OS customization" src="https://code.groundlight.ai/python-sdk/assets/images/rpi-imager-4-90702b146493c946266686450054a278.png" title="Rasterberry Pi Imager OS customization" width="651" height="766" class="img_wQsy"></p>
<p>When you're done configuring settings, click "Save" and then "Yes" to confirm.  Writing the image to the microSD card will take a few minutes.  When it's done, just pop the SD card into your pi, and power it up!  If it all works properly, you'll be able to access your Raspberry Pi over the network without needing to plug in a keyboard, mouse, or monitor.  (We like to plug it into Ethernet for the first boot, because we find that the Raspberry Pi's Wi-Fi can be a bit finicky, even if properly configured.)</p>
<h3 class="anchor anchorWithStickyNavbar_FNw8" id="no-code-machine-vision-with-monitoring-notification-server-mns">No-code machine vision with Monitoring Notification Server (MNS)<a href="https://code.groundlight.ai/python-sdk/blog/raspberry-pi-computer-vision#no-code-machine-vision-with-monitoring-notification-server-mns" class="hash-link" aria-label="Direct link to No-code machine vision with Monitoring Notification Server (MNS)" title="Direct link to No-code machine vision with Monitoring Notification Server (MNS)">‚Äã</a></h3>
<p>If you opted to install the <code>desktop</code> or <code>mns-headless</code> image, you'll have a web application called the <a href="https://github.com/groundlight/monitoring-notification-server" target="_blank" rel="noopener noreferrer">Groundlight Monitoring Notification Server (MNS)</a>,
which is a web application that allows you set up a computer vision pipeline without writing any code, and have it notify you when it detects something of interest.</p>
<p>After setting up your Raspberry Pi with Groundlight OS, wait a few minutes for it to finish downloading everything, and then access the MNS by navigating to <code>http://[your-raspberry-pi's-IP-address]:3000</code> in a web browser, or if you're running the desktop version, open <a href="http://localhost:3000/" target="_blank" rel="noopener noreferrer"><code>http://localhost:3000/</code></a>.</p>
<p><img loading="lazy" alt="MNS sample home screen" src="https://code.groundlight.ai/python-sdk/assets/images/mns-home-eb7c2b2cf6dfe022125a039681be0faf.png" title="MNS sample home screen" width="3104" height="1974" class="img_wQsy"></p>
<p>It will prompt you for your <a href="http://localhost:3000/python-sdk/docs/getting-started/api-tokens" target="_blank" rel="noopener noreferrer">Groundlight API token</a>, which you can get with a free account at <a href="https://app.groundlight.ai/" target="_blank" rel="noopener noreferrer">app.groundlight.ai</a>.  Then you can describe your visual query in natural language, and how you want the MNS to notify you when it detects something of interest.  For best-practices on how to describe your visual query, see <a href="https://code.groundlight.ai/python-sdk/blog/best-practices" target="_blank" rel="noopener noreferrer">this blog post</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_FNw8" id="get-started-for-free">Get Started for Free<a href="https://code.groundlight.ai/python-sdk/blog/raspberry-pi-computer-vision#get-started-for-free" class="hash-link" aria-label="Direct link to Get Started for Free" title="Direct link to Get Started for Free">‚Äã</a></h2>
<p>To start building your own computer vision solutions, sign up for a free account at <a href="https://app.groundlight.ai/" target="_blank" rel="noopener noreferrer">app.groundlight.ai</a>. Dive into Groundlight Pi-Gen for a hassle-free introduction to AI-powered computer vision on Raspberry Pi.</p>
<p>If you have any questions, please reach out to us on the in-application chat at <a href="https://app.groundlight.ai/" target="_blank" rel="noopener noreferrer">app.groundlight.ai</a> or on <a href="https://github.com/groundlight/python-sdk/issues" target="_blank" rel="noopener noreferrer">GitHub</a>.</p>]]></content:encoded>
            <category>raspberry-pi</category>
            <category>mns</category>
        </item>
        <item>
            <title><![CDATA[Best practices for best results with Groundlight]]></title>
            <link>https://code.groundlight.ai/python-sdk/blog/best-practices</link>
            <guid>https://code.groundlight.ai/python-sdk/blog/best-practices</guid>
            <pubDate>Fri, 15 Dec 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[How to get the best chance of success from Groundlight detectors]]></description>
            <content:encoded><![CDATA[<p>Want to get the best chance of success from your new Groundlight detectors? Here are five suggestions from the Groundlight science team that can help you get the best performance possible.</p>
<p>Come at it from the point of view of making answering your image query question as easy as possible.
Pretend you‚Äôre explaining the task to a novice. What would you need to do to set them up for success?</p>
<h2 class="anchor anchorWithStickyNavbar_FNw8" id="phrase-the-question-right">Phrase the question right<a href="https://code.groundlight.ai/python-sdk/blog/best-practices#phrase-the-question-right" class="hash-link" aria-label="Direct link to Phrase the question right" title="Direct link to Phrase the question right">‚Äã</a></h2>
<p>You will have more success asking questions that can in principle be answered by a reasonable person
simply by looking at a single image from the detector.</p>
<p>‚úÖ<!-- --> <strong>DO:</strong> "Is there a part staged in front of the robot ready for picking up?"<br>
<!-- -->‚ùå<!-- --> <strong>DON'T:</strong> "Am I awesome?"</p>
<p>Think about how you will use the output of your detector, so the Yes and No answers align with your expectations. A technically correct answer to a vague question may be of no use to you. For example, if you have a camera pointing down on a kitchen range and would like to get an alert if there's a fire, phrase the query so that normal gas burner flames are excluded.</p>
<p>‚úÖ<!-- --> <strong>DO:</strong> "Is there a fire in the pan? (Ignore normal gas burner flames)"<br>
<!-- -->‚ùå<!-- --> <strong>DON'T:</strong> "Is there a fire?"</p>
<hr>
<blockquote>
<p>üéì<!-- --> <em><strong>Pro Tip:</strong> If you want an alert on a rare event, it is better if the rare event corresponds to the answer of NO, not YES.</em></p>
<p>‚úÖ<!-- --> ‚ÄúAre indicator lights all green?‚Äù YES = correct operation, NO = alert<br>
<!-- -->‚ùå<!-- --> ‚ÄúIs there at least one red indicator light?‚Äù YES = alert, NO = correct operation</p>
<p>Here‚Äôs a <em>DON‚ÄôT DO THIS</em> example of a detector where the rare event (blocked fire extinguisher corresponds to the Yes class, which is less likely to result in good performance.</p>
<p><a target="_blank" href="https://code.groundlight.ai/python-sdk/assets/files/fire_extinguisher_blocked_yes-c8fc8eaf7c27b1f820cde8924b0f3d0f.png"><img loading="lazy" alt="Screenshot for a detector answering Yes when the fire extinguisher is blocked" src="https://code.groundlight.ai/python-sdk/assets/images/fire_extinguisher_blocked_yes-c8fc8eaf7c27b1f820cde8924b0f3d0f.png" title="A detector where the rare event (blocked fire extinguisher) corresponds to the Yes class, which is less likely to result in good performance" width="1396" height="264" class="img_wQsy"></a></p>
</blockquote>
<hr>
<h2 class="anchor anchorWithStickyNavbar_FNw8" id="put-details-in-the-notes">Put details in the notes<a href="https://code.groundlight.ai/python-sdk/blog/best-practices#put-details-in-the-notes" class="hash-link" aria-label="Direct link to Put details in the notes" title="Direct link to Put details in the notes">‚Äã</a></h2>
<p>Is any specialized knowledge required to answer your query?
Use the notes dialog to provide explanations of any assumed knowledge or definitions of technical terms.
Like in the fire extinguisher example above, consider adding short definitions inside the text of the query.</p>
<p>‚úÖ<!-- --> <strong>DO:</strong> ‚ÄúIs the fiducial (etched arrow on the gear surface) aligned with the painted chain link?‚Äù<br>
<!-- -->‚úÖ<!-- --> <strong>DO:</strong> ‚ÄúIs the fence fully closed? (Metal bar on the fence must be touching the plywood wall)‚Äù</p>
<p>Here‚Äôs an example of detailed notes for a detector asking ‚ÄúIs there a streetcar visible? READ NOTES‚Äù:</p>
<p><a target="_blank" href="https://code.groundlight.ai/python-sdk/assets/files/streetcar_visible_notes-139b16dc89faa933e71265525ae12574.png"><img loading="lazy" alt="Screenshot of detailed notes for a detector" src="https://code.groundlight.ai/python-sdk/assets/images/streetcar_visible_notes-139b16dc89faa933e71265525ae12574.png" title="Detailed notes for a detector asking &amp;quot;Is there a streetcar visible? READ NOTES&amp;quot;" width="1209" height="833" class="img_wQsy"></a></p>
<p>In this case, the customer even drew on the example images to point out where the street car might appear.
Detailed notes may be especially useful if the question is about a smaller region of the scene in the image.</p>
<h2 class="anchor anchorWithStickyNavbar_FNw8" id="think-of-edge-cases">Think of edge cases<a href="https://code.groundlight.ai/python-sdk/blog/best-practices#think-of-edge-cases" class="hash-link" aria-label="Direct link to Think of edge cases" title="Direct link to Think of edge cases">‚Äã</a></h2>
<p>How do you want to treat unclear or edge cases?
Sometimes it‚Äôs impossible to answer the question based on the image, for example, when it‚Äôs too dark
at night to tell, or the view is temporarily obstructed by something moving in front of the camera.
Do you know how you‚Äôd like to treat those cases?</p>
<p>‚úÖ<!-- --> <strong>DO:</strong> Add notes like ‚ÄúIf the image is too dark to tell, the answer should be YES.‚Äù</p>
<p>In the fire extinguisher example above, the customer wrote ‚ÄúIf you can‚Äôt see the fire extinguisher,
it is blocked‚Äù inside the query text, drawing attention to the most important potential edge case.</p>
<p>Detailed notes on foreseeable edge cases will prevent confusion by backend labelers and result in
quicker learning for your detector at less cost to you.</p>
<h2 class="anchor anchorWithStickyNavbar_FNw8" id="seed-with-a-few-examples">Seed with a few examples<a href="https://code.groundlight.ai/python-sdk/blog/best-practices#seed-with-a-few-examples" class="hash-link" aria-label="Direct link to Seed with a few examples" title="Direct link to Seed with a few examples">‚Äã</a></h2>
<p>It helps to add a few labels yourself early on, in order to provide good examples for backend labelers and the
new ML model. For best results, if you have example images for both YES and NO answers, send
them through early on, and add the corresponding labels. Having at least 2 customer ‚Äúground truth‚Äù
answers for each class of Yes or No will also give you ML performance metrics on your detector.</p>
<p><img loading="lazy" alt="Blue button before 2 examples of each class are provided" src="https://code.groundlight.ai/python-sdk/assets/images/label_button_before-e721de4cbaffbc4a25a69e88094fff76.png" width="215" height="144" class="img_wQsy"></p>
<h2 class="anchor anchorWithStickyNavbar_FNw8" id="only-you-know-the-truth">Only you know the truth<a href="https://code.groundlight.ai/python-sdk/blog/best-practices#only-you-know-the-truth" class="hash-link" aria-label="Direct link to Only you know the truth" title="Direct link to Only you know the truth">‚Äã</a></h2>
<p>Check periodically under the Flagged tab on your detector's detail page to see if any images may still be confusing. Click on the "Override Label" button to provide the correct answer in those cases.</p>
<p><a target="_blank" href="https://code.groundlight.ai/python-sdk/assets/files/flagged_images-f12e3efb68a3c2a072a25847fcbaaf37.png"><img loading="lazy" alt="Screenshot of image flagged as needing better examples" src="https://code.groundlight.ai/python-sdk/assets/images/flagged_images-f12e3efb68a3c2a072a25847fcbaaf37.png" title="Partial screenshot of a Flagged view" width="1011" height="255" class="img_wQsy"></a></p>
<p>It's also good practice to continue adding a few ground truth labels here and there by clicking on the ‚ÄúKeep labeling‚Äù button
on the detector details page, in order to get tighter confidence bounds on your detector‚Äôs performance metrics.</p>
<hr>
<blockquote>
<p>üéì<!-- --> <em>Watch this space for a forthcoming in-depth discussion of confidence bounds</em></p>
</blockquote>
<hr>
<p>If you notice labeling mistakes, correct them by providing your own answer. Then consider adding
extra instructions in the notes. You can upload screenshots or images inside the notes dialog too.
Our labeling staff will be notified whenever you make changes to your notes so they stay up to date with how you want your detector to behave and can quickly address misconceptions.</p>
<h2 class="anchor anchorWithStickyNavbar_FNw8" id="ready-to-start"><a href="https://app.groundlight.ai/" target="_blank" rel="noopener noreferrer">Ready to start?</a><a href="https://code.groundlight.ai/python-sdk/blog/best-practices#ready-to-start" class="hash-link" aria-label="Direct link to ready-to-start" title="Direct link to ready-to-start">‚Äã</a></h2>
<p>We hope these tips give you a great start. If you haven‚Äôt already, you can sign up for a free account at <a href="https://app.groundlight.ai/" target="_blank" rel="noopener noreferrer">https://app.groundlight.ai</a>. Dive into <a href="https://github.com/groundlight/groundlight-pi-gen" target="_blank" rel="noopener noreferrer">Groundlight Pi-Gen</a> for a hassle-free introduction to AI-powered computer vision on Raspberry Pi.</p>
<p>If you have any questions, please reach out to us on the in-application chat or via email to <a href="mailto:support@groundlight.ai" target="_blank" rel="noopener noreferrer">support@groundlight.ai</a>.</p>]]></content:encoded>
            <category>how-to</category>
            <category>best-practices</category>
        </item>
        <item>
            <title><![CDATA[Introducing Groundlight's FrameGrab Library]]></title>
            <link>https://code.groundlight.ai/python-sdk/blog/introducing-framegrab</link>
            <guid>https://code.groundlight.ai/python-sdk/blog/introducing-framegrab</guid>
            <pubDate>Wed, 06 Dec 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[We would like to introduce you to the FrameGrab library.]]></description>
            <content:encoded><![CDATA[<p>At Groundlight, we continue to build infrastructure that allows our customers to easily use computer
vision without a pre-existing dataset for industrial inspection, retail analytics, mobile robotics, and
much more. We've built many features towards the goal of declarative computer vision, and today we are excited to
introduce FrameGrab, a Python library designed to make it easy to grab frames from
cameras or streams.</p>
<p>FrameGrab supports generic USB cameras, RTSP streams, Basler USB cameras, Basler GigE cameras, and Intel RealSense depth cameras.</p>
<h2 class="anchor anchorWithStickyNavbar_FNw8" id="grabbing-camera-frames">Grabbing Camera Frames<a href="https://code.groundlight.ai/python-sdk/blog/introducing-framegrab#grabbing-camera-frames" class="hash-link" aria-label="Direct link to Grabbing Camera Frames" title="Direct link to Grabbing Camera Frames">‚Äã</a></h2>
<p>Frame grabber objects are configured through YAML. The configuration combines the camera type, camera ID, and the camera
options. The YAML config contains many configurable features, but only <code>input_type</code> is required. Valid choices for
<code>input_type</code> include</p>
<ul>
<li>generic_usb</li>
<li>rtsp</li>
<li>realsense</li>
<li>basler</li>
</ul>
<p>Here is an example of how to use the generic USB configuration</p>
<div class="language-python codeBlockContainer_aalF theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_MHx8"><pre tabindex="0" class="prism-code language-python codeBlock_zHgq thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_RjmQ"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> framegrab </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> FrameGrabber </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">config </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token triple-quoted-string string" style="color:#e3116c">"""</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">name: Front Door Camera</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">input_type: generic_usb</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">id:</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">  serial_number: 23432570</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">options:</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    resolution:</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        height: 1080</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        width: 1920</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    zoom:</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        digital: 1.5</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">"""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">grabber </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> FrameGrabber</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">create_grabber_yaml</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">config</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">frame </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> grabber</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">grab</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Do real work with the frame </span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Finally release the grabber object </span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">grabber</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">release</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup_Sd8_"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_LnQD" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_t3l1"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_IiZV"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>For the full set of configurable parameters, please refer to the <a href="https://github.com/groundlight/framegrab/tree/main" target="_blank" rel="noopener noreferrer">FrameGrab repository</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_FNw8" id="multi-cam-configuration">Multi-cam Configuration<a href="https://code.groundlight.ai/python-sdk/blog/introducing-framegrab#multi-cam-configuration" class="hash-link" aria-label="Direct link to Multi-cam Configuration" title="Direct link to Multi-cam Configuration">‚Äã</a></h2>
<p>If you have multiple cameras of the same type plugged in, we recommend you include serial numbers in the YAML config to
ensure proper pairing. The default pairing behavior is sequential (i.e., configurations will be paired with cameras in
a sequential ordering).</p>
<p>You can add serial numbers for multiple cameras like this</p>
<div class="language-yaml codeBlockContainer_aalF theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_MHx8"><pre tabindex="0" class="prism-code language-yaml codeBlock_zHgq thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_RjmQ"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">GL_CAMERAS</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">  - name: on robot arm</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">    input_type: realsense</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">    options: </span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">      depth:</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">        side_by_side: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">      crop:</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">        relative:</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">          right: .8</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">  - name: conference room</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">      input_type: rtsp</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">      id: </span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">        rtsp_url: rtsp://admin:password@192.168.1.20/cam/realmonitor?channel=1&amp;subtype=0</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">      options:</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">        crop:</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">          pixels:</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">            top: 350</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">            bottom: 1100</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">            left: 1100</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">            right: 2000</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">  - name: workshop</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">    input_type: generic_usb</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">    id:</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">      serial_number: B77D3A8F</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup_Sd8_"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_LnQD" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_t3l1"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_IiZV"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_FNw8" id="framegrab-autodiscovery-mode">FrameGrab Autodiscovery Mode<a href="https://code.groundlight.ai/python-sdk/blog/introducing-framegrab#framegrab-autodiscovery-mode" class="hash-link" aria-label="Direct link to FrameGrab Autodiscovery Mode" title="Direct link to FrameGrab Autodiscovery Mode">‚Äã</a></h2>
<p>Among other features, FrameGrab also includes autodiscovery mode. This allows you to automatically connect to all cameras
that are plugged into your machine (or discoverable on the network). Autodiscovery will load up default configurations
for each camera.</p>
<div class="theme-admonition theme-admonition-note admonition_LMjb alert alert--secondary"><div class="admonitionHeading_GGQ4"><span class="admonitionIcon_ifdW"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_pGk6"><p>Please note that RTSP streams cannot be autodiscovered in this manner. RTSP URLs must be pre-specified in the
configurations.</p></div></div>
<p>We recommend autodiscovery for simple applications where you don't need to set any special options on your cameras.
It is also a convenient method for finding the serial numbers of your cameras in case they are not printed on them.</p>
<p>Below is a short example of how to launch autodiscovery mode.</p>
<div class="language-python codeBlockContainer_aalF theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_MHx8"><pre tabindex="0" class="prism-code language-python codeBlock_zHgq thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_RjmQ"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> framegrab </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> FrameGrabber</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">grabbers </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> FrameGrabber</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">autodiscover</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Print some information about the discovered cameras</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> grabber </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> grabbers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">values</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">grabber</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">config</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Do real work </span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Release the frame grabber object </span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    grabber</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">release</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup_Sd8_"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_LnQD" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_t3l1"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_IiZV"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_FNw8" id="using-framegrab-for-motion-detection">Using FrameGrab for Motion Detection<a href="https://code.groundlight.ai/python-sdk/blog/introducing-framegrab#using-framegrab-for-motion-detection" class="hash-link" aria-label="Direct link to Using FrameGrab for Motion Detection" title="Direct link to Using FrameGrab for Motion Detection">‚Äã</a></h2>
<p>With this release, we also continue to support <a href="https://en.wikipedia.org/wiki/Motion_detection" target="_blank" rel="noopener noreferrer">motion detection</a> via frame differencing, a
fast algorithm for easily detecting motion in a sequence of frames.</p>
<p>To use motion detection, initialize the MotionDetector instance with the desired percentage of pixels
needed to change in an image for it to be flagged for motion and the minimum brightness change for each pixel for it
to be considered changed. Here is a comprehensive example.</p>
<div class="language-python codeBlockContainer_aalF theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_MHx8"><pre tabindex="0" class="prism-code language-python codeBlock_zHgq thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_RjmQ"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> framegrab </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> FrameGrabber</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> MotionDetector</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">config </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">'input_type'</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">'webcam'</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">grabber </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> FrameGrabber</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">create_grabber</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">config</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">motion_detector </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> MotionDetector</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">pct_threshold</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">motion_threshold</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> val_threshold</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">60</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">while</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    frame </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> grabber</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">grab</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> frame </span><span class="token keyword" style="color:#00009f">is</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"No frame captured!"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">continue</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> motion_detector</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">motion_detected</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">frame</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"Motion detected!"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup_Sd8_"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_LnQD" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_t3l1"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_IiZV"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_FNw8" id="conclusion">Conclusion<a href="https://code.groundlight.ai/python-sdk/blog/introducing-framegrab#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">‚Äã</a></h2>
<p>Recent releases of FrameGrab add various easy to use features. We now support
multiple camera types and continue to support motion detection.</p>
<p>If you encounter any issues while using FrameGrab, please feel free to file an issue in our <a href="https://github.com/groundlight/framegrab" target="_blank" rel="noopener noreferrer">GitHub repository</a>
and while there, review guidelines for <a href="https://github.com/groundlight/framegrab#contributing" target="_blank" rel="noopener noreferrer">contributing</a> to this library.</p>]]></content:encoded>
            <category>groundlight-extensions</category>
            <category>framegrab</category>
        </item>
    </channel>
</rss>